GPI Data Pipeline Installation and Configurationv0.9draftData Reduction system for the Gemini Planet ImagerManual by: Marshall Perrin (STScI), Jérôme Maire (University of Toronto), and René Doyon (Université de Montreal) 
Table of ContentsI.   IntroductionIIa.   Installing the GPI Data Pipeline From SourceIIb. Installing the GPI Data Pipeline From Knowledge TreeRequirementsObtaining and Installing the Zip FilesRelated programs: GPItv and DSTIIc. Alternative: installing the IDL Virtual Machine and DRP executablesObtaining and Installing the IDL Virtual MachineInstalling the VM on WindowsInstalling the VM on UNIX / LinuxInstalling the VM on MacintoshIII. Configuring the PipelineConfiguring Environment VariablesConfiguration Filespipeline_settings.txtIVa. Starting the Pipeline - from sourceIVb. Starting the Pipeline - from the IDL Virtual Machine and executablesStarting DRP executables with the VMStarting DRP executables on Windows systemStarting DRP executables on UNIX/Linux systemStarting DRP executables on Mac OS X systemV. Getting access to the data (GPI team only)Installing the VOSpace File SystemMounting the GPI VOspaceCredits
I.   Introduction This document describes how to install the GPI data pipeline and configure it. There are three different general methods by which the pipeline can be installed. These are described in the following sections of the manual.? Section IIa: Installation from source code directly from the subversion repository (appropriate for GPI team members and Gemini staff who may be editing pipeline code)? Section IIb: Installation from zip files of code stored online (on the Knowledge Tree right now, eventually probably some web page), for users who have their own licensed copies of IDL.? Section IIc: Installation of compiled IDL code to run in the IDL Runtime environ-ment, for users who do not have their own copies of IDL. Once the pipeline is installed, a handful of configuration items such as file paths need to be set to enable it to work properly. Some additional optional configuration parameters can modify pipeline behavior or set user preferences. RequirementsThe GPI Data Pipeline is written in IDL, so all users will need to have a copy of IDL, either the full IDL program or the IDL runtime environment. If you have a full copy of IDL installed, proceed to section IIa or IIb. If you have the IDL runtime, or do not yet have IDL installed at all, proceed to section IIc.The pipeline is supported on IDL version 7.0 or more recent at present, but may at some future point require IDL 8.  While it may be possible to run some of the pipeline code on IDL 6, this is not supported (note, IDL 7 was released in 2007, so IDL 6 is > 6 year old software at this point).   IDL 8 is recommended.Mac, Linux and Windows platforms are all supported. There are no particular dependencies on operating system versions.Note: There was at one point a graphical installation tool written in Python by Marshall Perrin. This is not maintained right now and no longer works, but could be revived later if needed. 
IIa.   Installing the GPI Data Pipeline From SourceThis section describes how to install the pipeline in development mode, for members of the GPI team and Gemini staff. This section requires you have an IDL license. If you do not have an IDL license, please refer to section IIc for installing the compiled DRP executables instead.The GPI Pipeline souce code is developed using a Subversion version control repository hosted at the SETI Institute.  GPI team members should see the GPI Computer Account Setup document for instructions to obtain an account on this repository.? N.B.: If you are not familiar with version control, see this intro to version control: http://betterexplained.com/articles/a-visual-guide-to-version-control/Once you have that account, in a directory of your choosing (preferably somewhere inside your $IDL_PATH) execute the commands1 svn checkout https://repos.seti.org/gpi/pipeline --username <yourusername>2 svn checkout https://repos.seti.org/gpi/gpitv --username <yourusername>3 svn checkout https://repos.seti.org/gpi/external --username <yourusername>The above commands will download the GPI data pipeline, GPItv viewer, and a directory containing external dependencies of the code, for instance the Goddard IDL library, the Coyote library, etc. You may already have copies of many of these external routines in your own IDL library, in which case you can delete the excess copies from this directory if you so desire. Proceed now to section III on how to configure the pipeline. 
IIb. Installing the GPI Data Pipeline From Zip FilesThis section describes how to install the pipeline from Zip files containing released source code of the pipeline. This is appropriate for anyone who has a full copy of IDL, but does not immediately intend to contribute to ongoing pipeline development. This section requires an IDL license. Please refer to section IIc if you do not have an IDL license for installing the compiled DRP executables for use with the IDL runtime.RequirementsWARNING: As of March 2012, the files on the KT are not kept up to date - this documentation section is just a placeholder for sometime later when those files are updated. Use the subversion repository for now. Obtaining and Installing the Zip FilesThe pipeline code and its manual is available from the KT website:   http://dms.hia.nrc.ca/browse.php?fFolderId=1802The GPItv software and manual are available from the KT website:    http://dms.hia.nrc.ca/browse.php?fFolderId=1801Unzip these files in a directory that is a part of your IDL path.  Proceed now to section III on how to configure the pipeline. 
IIc. Installing the IDL Virtual Machine and DRP executables If you do not have an IDL license, this section describes how to install the free IDL Virtual Machine and how to install and run the GPI DRP as compiled code.FIXME – update following to current IDL version.Obtaining and Installing the IDL Virtual MachineIf you do not have a licensed version of the IDL package, you will need to download and install the IDL Virtual Machine (VM). The IDL Virtual Machine is a free runtime version of IDL available from ITT Excelis at http://www.exelisvis.com/. The next section describes how to install the IDL Virtual Machine 8.0 but it can be applied to any version.Installing the IDL VM on Windows ? There are two installation packages:? idl80win32_setup.exe for 32-bit Windows systems? idl80win64_setup.exe for 64-bit Windows systems Note: If you have a 64-bit Windows system, use the 64-bit installation package. It includes both 32-bit and 64-bit versions of IDL.? You need Administrator privileges to install IDL. If you do not have such privileges, the installation process will fail because it cannot modify the system configuration. To download and install IDL: 1 Click on the link to download IDL 8.0. 2 In the Save As dialog, specify a location to save the executable file you are downloading (idl80win32_setup.exe for 32-bit Windows or idl80win64_setup.exe for 64-bit Windows) and click Save. 3 After the download is complete, go to the location where you saved the idl80win32_setup.exe or idl80win64_setup.exe file and double click on it to begin installing IDL. 4 Click Setup, and follow the prompts to install IDL.Installing the VM on UNIX / LinuxBefore you begin: ? If you plan to install IDL in a public directory, be sure you have root (or similar) permissions before running the installer. To download and install IDL: 1 Choose a place to install IDL on your system and create that directory. The default installation path is /usr/local/itt.If you need to create the directory, be sure you have root (or similar) permissions, and issue the following commands:% mkdir /usr/local/itt (to create)  % chmod a+rx /usr/local/itt (to give access)   2 Select the appropriate download link for your UNIX platform. Click on the link to download IDL 8.0. The IDL installation file is a compressed archive; save it in the directory in which you are installing IDL (/usr/local/itt by default). 3 Unpack the archive. First uncompress the file by entering:% gunzip idl80platform.tar.gz  then untar the file:% tar xf idl80platform.tar   where platform is the platform type. 4 Now execute the installation program by entering the following command:% ./install.sh  5 Follow the prompts to install IDL.6 If you choose not to create symbolic links, you can set up IDL by issuing the following command: source Install_dir/idl/idl80/bin/idl_setupwhere Install_dir is the main installation directory. Then run the IDL application.Installing the VM on Macintosh Before you begin:? The Apple X11 Window System must be installed for Mac OS X; it is not installed by default. Obtain this from Apple. For Mountain Lion or newer versions of OS X, obtain the free XQuartz software from http://xquartz.macosforge.org.To download and install IDL: 1 Click on the link to download the full version of IDL 8.0. Note the location to which you are downloading the PKG file. 2 Double-click the file InstallIDL80_Mac.pkg.3 Follow the prompts to install IDL.Obtaining and installing the GPI DRP ExecutablesFIXME – update following to reflect updated ZIP files, and move them off of the KT onto some other web siteThe executables are packaged as a zip file, GPI-DRPexec.zip, which can be opened on any of  Linux, Mac and Windows systems.  The pipeline executables are available from the KT website:Not updated on KT right now - see note above in IIb.Updated version as of June 7, 2012 (untested): http://di.utoronto.ca/~maire/pipeline.zipObtain this zip file and uncompress it to a directory of your choosing. Remember this path for use when setting DRP paths in the next section.The zip file contains a directory called pipeline which contains .sav files needed by the Virtual Machine to run the pipeline:? gpipiperun.sav starts the controller? gpitv.sav starts GPItv? launch_drp.sav starts an application that will allow the user to start the DRF-GUI, the Parser, GPItv, in addition to some other applications not necessary here.FIXME – update following It contains also the following directories:? dpl_library: this directory contains 5 filter transmission FITS files, a drsconfig.xml file (description of primitives and their parameters needed by the DRP), the 6th Catalog of Orbits of Visual Binary Stars orb6orbits.txt,? drf_queue: this empty directory will be automatically scanned by the controller for new DRFs to be executed,? drf_templates: this directory contains the template DRF that will be used by the parser to define which recipes should be used for a specific dataset.? IDLxx: this directory contains IDL files needed to run the pipeline with the Virtual Machine. ? log: this empty directory serves to place the DRP log file of every reduction processed.If you have followed these steps successfully, you have installed the pipeline code. Proceed now to section III on how to configure the pipeline. 
III. Configuring the PipelineThe GPI data reduction pipeline relies on a variety of configuration information. This can roughly be divided into three categories:1 Environment variables that define some basic locations of interest in the file system. For instance, the variable $GPI_DRP_QUEUE_DIR defines the queue directory that is watched for new reduction scripts to execute, while $GPI_RAW_DATA_DIR defines where the pipeline should look for new raw data files.2 Configuration text files that define various options and settings. This follows the convention common to many Unix programs in that there is one system-wide configuration file that sets defaults for all settings, and then a user may optionally have a file in their home directory that overrides the settings. System default settings are stored in the file ‘config/pipeline_settings.txt’ provided with the pipeline software. Users may optionally create a file in their home directory if they wish to change any of the values away from the defaults. On Unix computers (including MacOS), the user configuration file is named “.gpi_pipeline_settings” in the users’s home directory. On Windows, the user configuration file is namedThe format of these files is very simple, just “key     value” on each line.  3 And ancillary data files that should rarely, if ever, need to be changed. For instance, there is a file containing the orbital elements of calibration binaries, while another file describes the wavelengths of emission lines in the Xenon wavelength calibration lamp at Gemini. These files are provided with the pipeline code in a subdirectory “config”. When installing the pipeline for the first time, you will (at a minimum) need to set some file paths as appropriate for your site, most easily by defining environment variables. You may also wish to create a user settings file and edit its settings if you wish to change any of the defaults, but this is not required. The available options are described below.  Configuring Directory PathsPipeline operation requires several paths to be set. Only a few paths are explicitly required to be set; the rest have default settings that should work for the majority of users (but may be changed if desired). To ease the setup and confirguration process, there are sample shell scripts “setenv_GPI_sample.{csh/bash}” in the pipeline/scripts subdirectory that demonstrate how to set up your environment for *nix and Mac OS systems.  An IDL program is also included for Windows users. The path variables which are required are:VariableContainsExampleGPI_DRP_QUEUE_DIRPath to queue directory /home/username/gpi/queueGPI_RAW_DATA_DIRDefault path for FITS file input /some/network/disk/gpi/rawdataGPI_REDUCED_DATA_DIRPath to save output files /some/network/disk/gpi/reducedGPI_DRP_DIRPath to DRP IDL code/home/username/IDL/gpi/pipelineNote that the user must have write permissions to the $GPI_DRP_QUEUE_DIR and $GPI_REDUCED_DATA_DIR. The raw data  dir may be read-only.   GPI Team Only: For GPI instrument team members who are pulling data directly from VOSPACE, make sure that your Reduced and Queue directories are local, and do not also point to the VOSPACE.  See the setenv_GPI_sample files for more details.The additional optional path settings are as follows :VariableContains Default Value if Not Set ExplicitlyGPI_DRP_DIRRoot dir of pipeline software  (Determined automatically as the location of the IDL pipeline code.)GPI_DRP_CONFIG_DIRPath to directory containing pipeline config files and ancillary data. $GPI_DRP_DIR/configGPI_DRP_TEMPLATES_DIRPath to recipe templates$GPI_DRP_DIR/recipe_templatesGPI_CALIBRATIONS_DIRLocation of Calibration Files DB $GPI_REDUCED_DATA/calibrationsGPI_DRP_LOG_DIRPath to save output log files $GPI_REDUCED_DATA/logsAlso note that all directories must actually exist, and those that will be written to (queue, reduced, calibrations, and log) must have write permissions for the user running the pipeline.On Mac or Linux, the best approach is probably to make a copy of setenv_GPI_sample.{csh/bash} in your home directory, edit the copied file to set paths as desired for your machine, and then add a line to your shell startup file to source that edited file in the usual manner.  (e.g. source ~/setenv_GPI_config.xxx)Environment variables are set in the typical manner:csh:   setenv GPI_DRP_QUEUE_DIR ~/GPI/pipeline/drf_queue       bash:  export GPI_DRP_QUEUE_DIR=”~/GPI/pipeline/drf_queue”After you have configured these variables, on Unix & Mac you can check them by printing their values at the shell:      > print $GPI_RAW_DATA_DIR      > env | grep GPI	On Windows, environment variables can be set from within IDL. For instance,setenv,'GPI_DRP_QUEUE_DIR=E:\pipeline\drf_queue\'They can also be set from the Control Panel’s system settings dialog.  The best approach may be to copy the sample code setenv_gpi_windows.pro to somewhere in your IDL path.  Edit the script as necessary, and then add it to your idl startup file.If valid environment variables are not found during pipeline startup, a dialog will be displayed to alert the user of this fact. The required paths must be set before you can proceed. Additional Note: In addition to setting environment variables, the above directory names may also be set in the configuration files (as described below). The environment variables, if set, will override those.  For historical reasons, environment variables are the preferred way to set paths (and they also are convenient for use interactively in the shell, for instance you can ‘cd $GPI_RAW_DATA_DIR’, etc.). But, if desired for some reason, it is possible to set paths using just the text config files. Configuration FilesAs noted above, the config file system is similar to many other Unix programs in that there is one file that sets the system default settings, and then a user may optionally have a dotfile in their home directory that overrides those settings. System default settings are stored in the file ‘config/pipeline_settings.txt’ provided with the pipeline software. Users may optionally create a file “~/.gpi_pipeline_settings” in their home directory to change any of the values away from the defaults.Note for Subversion Users: If you have installed from the Subversion repository, don’t  modify the system default configuration file ‘config/pipeline_settings.txt’. If you did that, whenever you updated your code from subversion it may overwrite your configuration.  Instead, make changes to a local user config file in your home directory:      cp pipeline/config/pipeline_settings.txt ~/.gpi_pipeline_settingsYou can then edit your individual settings as desired.  Alternatively, just leave this file blank or nonexistent and the default settings will be used. Configuration file contents: The GPI pipeline has adopted an extremely simple text file format. Each line of is just  SETTING_NAME<tab>SETTING_VALUESettings are case insensitive. Values are all returned as strings.  Boolean parameters are entered as 0 or 1. The allowable settings are as follows. Many users will not need to adjust any of these. Setting NamePossible ValueMeaningstrict_validation0,1Strictly enforce checking of input data - any data which does not validate OK as a GPI file is ignored. If turned off (0), will attempt to preprocess files to fix missing keyword headers etc during I&T so the data can be processed anyway.organize_raw_data_by_dates0,1Should we expect raw data to be organized in directories by date underneath $GPI_RAW_DATA_DIR? If so, data should be in directories named according to YYMMDD such as 130401 for 2013 April 01.organize_reduced_data_by_dates0,1Should reduced data be output in directories organized by data under $GPI_DRP_OUTPUT_DIR? Such directories will be created if needed. organize_DRFs_by_dates0,1Should saved DRFs be output in directories organized by data under $GPI_DRP_OUTPUT_DIR? Such directories will be created if needed. parsergui_auto_queue0,1Should the Parser GUI automatically add to the queue the DRFs that it produces?autogui_write_drfs_toreducedWhere should the Automatic Reducer GUI save the DRFs that it produces? (TBC - not sure this is implemented??)autogui_auto_queue0,1Should the Auto Reducer GUI automatically add to the queue the DRFs that it produces?max_files_per_drf<integer>Maximum number of input FITS files allowed in a single data reduction recipe. This is used to allocate some internal arrays. Currently set to 200, but can be made arbitrarily larger if needed, memory permitting.prompt_user_for_questionable_data0,1if set, when the pipeline encounters a “questionable” (aborted/lousy seeing/otherwise flagged as bad DQ) frame, it should ask the user whether to process that file or not. If this is not set, the pipeline will silently discard the file.prompt_user_for_outputdir_creation0,1If set to zero, whenever you need to create a directory to save some requested filename (e.g. for storing output files or DRFs), just go ahead and do so without asking the user about it. If set, ask the user first before creating the directory.ifs_lenslet_scale<float>Lenslet spatial scale of the IFS, in arcseconds/lenslet. Currently believed to be 0.01409, very close to the design value of 0.014memsrotation<float>The rotation of the DM (or equivalently the edges of the dark hole) with respect to the satellite spots, such that the rotation of the dark hole in the processed IFS cubes is given by SO3(\theta) where \theta = mean(satang) - memsrot, and satang is the array of the calculated rotations of the four satellite spots.  This value is currently empirically determined to be 1 degree, and has units of radians.pix_to_ripple<float>Twice the number of pixels between the image center (defined as the center of the sat spots) and the MEMS ripple (i.e., twice the distance to the highest controllable frequency).  Note that this is a lateral and not radial measurement (i.e., the edge of the dark is located pix_to_ripple/2. away from the center in the reference frame given by memsrotation). Equivalently, pix_to_ripple is equal to the radial distance between waffle spots, divided by \sqrt{2}.  Theoretically, this value should be given by  pix_to_ripple =  44*\lambda*1d-6/8* 180/\pi*3600/pixscl, or approximately 122.534 pixels for the first slice of H band (1.5121622 \mu m).  In practice, it varies from this value by about 1 to 3 pixels, depending on the system state.enable_primitive_debug0,1If set, IDL code errors in primitives will stop at a breakpoint, rather than continuing execution of the pipeline and just marking that recipe file as failed.enable_parser_debug0,1Enable more verbose debugging output from data parser.gpitv_default_scalelinear, log, sqrt, asinh, histeqSets the default scale for newly opened gpitv windows gpitv_cur_image_sticky0,11: Open new images to the same slice as current image is on. 0: Open all images to the same default slice.gpitv_default_align0,1Toggle auto alignment for newly loaded images.gpitv_default_autoscale0,1Toggle autoscaling for newly loaded images.gpitv_default_stretch0,11: Preserve min/max from previous image. 0: Recalculate for each new image.gpitv_autozoom0,1Toggle autozoom for newly loaded images.gpitv_showfullpaths0,1Toggle to show the full path to files in the gpitv titlebar.gpitv_noinfo0,1Toggle suppression of informational messages.gpitv_nowarn0,1Toggle suppression of warning messages.
IVa. Starting the Pipeline - from sourceThe pipeline expects to run in two different IDL sessions: one for the data processing and one for the graphical interfaces. On Linux or Mac, a script is provided in pipeline/scripts that starts 2 xterms, each with an IDL session, and runs the two appropriate commands:      shell> gpi-pipelineYou should see two xterms appear, both launch IDL sessions, and various commands run. If in the second xterm you see a line reading “Now polling for data in such-and-such directory” at the bottom, and the GPI Status Console and Launcher windows are displayed, then the pipeline has launched successfully.On Windows: Start an IDL session. Run      IDL> gpipiperunStart a second IDL session. Run     IDL> launchdrpYou should now have two IDL seeOnce that is running:You may now proceed to the GPI Pipeline User’s Manual section 2 and proceed from there.     
IVb. Starting the Pipeline - from the IDL Virtual Machine and executablesStarting DRP executables with the VM The compiled binary versions of DRP applications that can be started with the IDL Virtual Machine are:? gpipiperun.sav starts the pipeline controller, the administration console? gpitv.sav starts GPItv? launch_drp.sav starts an application that will allow the user to start the DRF-GUI, the Parser, GPItv, in addition to some other applications (DRF queue viewer, DST).? autom.sav starts the Online ModeThis section explains how you run a .sav file in the IDL Virtual Machine depends on your operating system: Starting DRP executables on Windows systemWindows users can drag and drop the .sav file onto the IDL Virtual Machine desktop icon, launch the IDL Virtual Machine and open the .sav file, or launch the.sav file in the IDL Virtual Machine from the command line. If you have a copy of the IDL installation CD-ROM, you can also run the .sav file directly from the CD-ROM without installing IDL. Using Drag and Drop To use drag and drop: 1 Locate and select the .sav file in Windows Explorer. 2 Drag the file icon from the Windows Explorer list and drop it onto the IDL Virtual Machine 8.0 icon that has been created for you on the desktop. The IVM window is displayed. 3 Click anywhere in the IDL Virtual Machine window to close the window and run the .sav file.Using the IDL Virtual Machine Icon To open a .sav file from the IDL Virtual Machine: 1 Do either of the following to launch the IDL Virtual Machine and display the IDL Virtual Machine window: Select Start ??Programs ??IDL 6.4 ?IDL Virtual Machine or Start ?Programs??IDL Virtual Machine 6.4, ?IDL ? Double-click the IDL Virtual Machine 6.4 desktop icon. 2 Click anywhere in the IDL Virtual Machine window to close the window and display the file selection menu. 3 Locate and select the .sav file, and double-click or click Open to run it. Running from the Windows Command Line To run a .sav file from the command line prompt: 1 Open a command line prompt. Select Run from the Start menu, and enter cmd. 2 Change directory (cd) to the IDL_DIR\bin\bin.platform directory where platform is the platform-specific bin directory. 3 Enter the following at the command line prompt:idlrt -vm=<path><filename>   where <path> is the path to the .sav file, and <filename> is the name of the .sav file.Starting DRP executables on UNIX/Linux system UNIX users must launch the IDL Virtual Machine from the UNIX command line. To run a .sav file in the IDL Virtual Machine: 1 Enter the following at the UNIX command line:idl -vm=<path><filename>   where <path> is the complete path to the .sav file and <filename> is the name of the .sav file. The IDL Virtual Machine window is displayed. 2 Click anywhere in the IDL Virtual Machine window to close the window and run the .sav file.To launch the IDL Virtual Machine and use the file selection menu to locate the .sav file to run: 1 Enter the following at the UNIX command line:idl -vm  The IDL Virtual Machine window is displayed.2 Click anywhere in the IDL Virtual Machine window to close the window and display the file selection menu.3 Locate and select the .sav file and click OK.Starting DRP executables on Mac OS X systemMacintosh users can drag and drop the .sav file onto the IDL Virtual Machine desktop icon, launch the IDL Virtual Machine and open the .sav file, or launch the.sav file in the IDL Virtual Machine from the command line. Using Drag and Drop To use drag and drop: 1 Locate and select the .sav file in the Finder. 2 Drag the file icon from the Finder and drop it onto the IDL 8.0 Virtual Machine icon that has been created for you on the desktop. The IDL Virtual Machine window is displayed. 3 Click anywhere in the IDL Virtual Machine window to close the window and run the .sav file.Using the IDL Virtual Machine Icon To open a .sav file from the IDL Virtual Machine: 1 Double-click the IDL 6.4 Virtual Machine icon to display the IDL Virtual Machine window: 2 Click anywhere in the IDL Virtual Machine window to close the window and display the file selection menu. 3 Locate and select the .sav file and click OK.Running from the Command Line To run the IDL Virtual Machine from the UNIX command line: 1 Enter the following at the UNIX command line:idl -vm=<path><filename>   where <path> is the complete path to the .sav file and <filename> is the name of the .sav file. The IDL Virtual Machine window is displayed.2 Click anywhere in the IDL Virtual Machine window to close the window and run the .sav file.To launch the IDL Virtual Machine and use the file selection menu to locate the .sav file to run: 1 Enter the following at the UNIX command line:idl -vm   The IDL Virtual Machine window is displayed.2 Click anywhere in the IDL Virtual Machine window to close the window and display the file selection menu. 3 Locate and select the .sav file and click OK.
V. Getting access to the data (GPI team only)This section of instructions is specific to the GPI instrument team and Gemini staff who need access to Integration & Test data. Regular GPI observers will retrieve their data from the CADC archive in the usual manner for all Gemini observations. The GPI team uses the VOspace (a shared “cloud” storage service provided by CADC) to store and share instrument data.(The following instructions for VOspace setup are copied from the GPI Campaign wiki at https://sites.google.com/site/gpisciencecampaign/home/data-archive/vospace) Installing the VOSpace File SystemFollow the instructions on  http://canfar.phys.uvic.ca/wiki/index.php/VOSpace_filesystem. To briefly summarize them, you will need to do the following steps - but you should consult that linked page for the full detailed instructions. ? for Macs, you will need to install OSX-FUSE, then install the vos python package. Note: Make sure when you install OSX-FUSE, you check the checkbox for “MacFUSE compatibility Layer”. ? For Linux, you will install fuse and then install the vos python package. Note: You may need to set an environment variable if you get an error about being unable to find the libfuse library. This is not needed on all machines. If you do encounter this problem, you should do      csh/tcsh:	setenv DYLD_FALLBACK_LIBRARY_PATH /usr/local/lib/      bash: 	export DYLD_FALLBACK_LIBRARY_PATH=/usr/local/lib/If you find that you need to do this, you should set it in your shell configuration files so the setting is permanent. Mounting the GPI VOspace1 Run:        getCertThis will ask for your CADC username and password. This saves an encrypted access token in your home directory giving you permission to access the VOspace. It times out after 10 days, at which point you will need to run getCert again. Optionally you can say      getCert --daysValid=30 to get a longer access. (30 is the max allowable)2 Test with       vls vos:gpiYou should see some list of files as the output, including subdirectories like “GPI-UCSC-commissioning”, “DRP-test-data”, etc. Note: If you get an error at this point, see the part above about setting an enviroment variable for DYLD_FALLBACK_LIBRARY_PATH. 3 Create some directory as the mount point you would like for your data. For instance      mkdir /home/myusername/data/gpidata 4 Mount the VOspace to this directory. (The following should all be entered on one line in your terminal, it’s just split as multiple lines here because it’s too long) mountvofs --vospace vos:gpi   --mountpoint /home/myusername/data/gpidataYou should then be able to access VO files in that directory with ls, or view them in the Finder, etc., just as if they were on the local machine.  Note, access will be kind of slow because it’s going over the network. Don’t be surprised if it takes several seconds for ls.   ? How to unmount:a Mac:umount /home/myusername/data/gpidatab Linux:fusermount -u /home/myusername/data/gpidata5 You can optionally set up a cache that will save accessed files for more rapid access. For instance I do this on my machine:       mountvofs --vospace vos:gpi        --mountpoint /Users/mperrin/data/gpi/vo        --cache_dir /Users/mperrin/tmp/vocache        --cache_limit=30000000000For help with any problems with VOspace, contact Christian Marois or JJ Kavelaars <JJ.Kavelaars@nrc-cnrc.gc.ca>. Note, the VOspace can be pretty slow. You may find it useful to just rsync or copy large sets of data on to your local disk for improved access. The VO developers are actively working to make the system faster, but this will be a gradual process. 
CreditsPipeline coding by Jerome Maire and Marshall Perrin, with contributions from other members of the GPI team. The pipeline architecture was inspired by, and portions of the backbone code re-used from, the Keck OSIRIS pipeline.  The OSIRIS pipeline was developed by James Larkin, Shelley Wright, Jason Weiss, Mike McElwain, Marshall Perrin, Christof Iserlohe, Alfred Krabbe,          Tom Gasaway, and Tommer Wizanski. The DRFGUI was inspired by the OSIRIS ODRFGUI in Java by Jason Weiss. Jerome Maire reimplemented it in a modified form in IDL, with assistance from Marshall Perrin.The first version of this manual was primarily by Jerome Maire. This current version has been edited and expanded mostly by Marshall Perrin.  GPI Pipeline Installation Manual								23 